{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:12.726035Z",
     "iopub.status.busy": "2025-03-29T17:56:12.725737Z",
     "iopub.status.idle": "2025-03-29T17:56:14.221845Z",
     "shell.execute_reply": "2025-03-29T17:56:14.220773Z",
     "shell.execute_reply.started": "2025-03-29T17:56:12.726004Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/open-clip'...\n",
      "remote: Enumerating objects: 3678, done.\u001b[K\n",
      "remote: Counting objects: 100% (3678/3678), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1411/1411), done.\u001b[K\n",
      "remote: Total 3678 (delta 2231), reused 3612 (delta 2165), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (3678/3678), 15.32 MiB | 36.16 MiB/s, done.\n",
      "Resolving deltas: 100% (2231/2231), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/nickxir12/MyCLIP_first_repo.git /kaggle/working/open-clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T18:21:24.942872Z",
     "iopub.status.busy": "2025-03-29T18:21:24.942560Z",
     "iopub.status.idle": "2025-03-29T18:21:26.330693Z",
     "shell.execute_reply": "2025-03-29T18:21:26.329817Z",
     "shell.execute_reply.started": "2025-03-29T18:21:24.942850Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/open-clip'...\n",
      "remote: Enumerating objects: 3688, done.\u001b[K\n",
      "remote: Counting objects: 100% (3688/3688), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1418/1418), done.\u001b[K\n",
      "remote: Total 3688 (delta 2237), reused 3619 (delta 2168), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (3688/3688), 15.33 MiB | 31.51 MiB/s, done.\n",
      "Resolving deltas: 100% (2237/2237), done.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Delete the old repo (if it exists)\n",
    "!rm -rf /kaggle/working/open-clip  \n",
    "\n",
    "# Step 2: Clone the latest version from GitHub\n",
    "!git clone https://github.com/nickxir12/MyCLIP_first_repo.git /kaggle/working/open-clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:15.494973Z",
     "iopub.status.busy": "2025-03-29T17:56:15.494679Z",
     "iopub.status.idle": "2025-03-29T17:56:24.051542Z",
     "shell.execute_reply": "2025-03-29T17:56:24.050403Z",
     "shell.execute_reply.started": "2025-03-29T17:56:15.494951Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting braceexpand\n",
      "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Installing collected packages: braceexpand\n",
      "Successfully installed braceexpand-0.1.7\n",
      "Collecting webdataset\n",
      "  Downloading webdataset-0.2.111-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from webdataset) (0.1.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from webdataset) (1.26.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from webdataset) (6.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->webdataset) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->webdataset) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->webdataset) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->webdataset) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->webdataset) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->webdataset) (2024.2.0)\n",
      "Downloading webdataset-0.2.111-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: webdataset\n",
      "Successfully installed webdataset-0.2.111\n"
     ]
    }
   ],
   "source": [
    "#!pip install open_clip_torch\n",
    "!pip install braceexpand\n",
    "!pip install webdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:24.053793Z",
     "iopub.status.busy": "2025-03-29T17:56:24.053505Z",
     "iopub.status.idle": "2025-03-29T17:56:27.737299Z",
     "shell.execute_reply": "2025-03-29T17:56:27.736250Z",
     "shell.execute_reply.started": "2025-03-29T17:56:24.053769Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 1)) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 2)) (0.20.1+cu121)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 3)) (2024.11.6)\n",
      "Collecting ftfy (from -r /kaggle/working/open-clip/requirements.txt (line 4))\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 5)) (4.67.1)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 6)) (0.29.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 7)) (0.4.5)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/working/open-clip/requirements.txt (line 8)) (1.0.12)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (11.0.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->-r /kaggle/working/open-clip/requirements.txt (line 4)) (0.2.13)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->-r /kaggle/working/open-clip/requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->-r /kaggle/working/open-clip/requirements.txt (line 6)) (2025.1.31)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision->-r /kaggle/working/open-clip/requirements.txt (line 2)) (2024.2.0)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ftfy\n",
      "Successfully installed ftfy-6.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /kaggle/working/open-clip/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T18:21:29.239522Z",
     "iopub.status.busy": "2025-03-29T18:21:29.239219Z",
     "iopub.status.idle": "2025-03-29T18:21:29.243864Z",
     "shell.execute_reply": "2025-03-29T18:21:29.243102Z",
     "shell.execute_reply.started": "2025-03-29T18:21:29.239499Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/working/open-clip/src\")\n",
    "sys.path.append(\"/kaggle/working/open-clip/src/open_clip\")\n",
    "sys.path.append(\"/kaggle/working/open-clip/src/open_clip_train/my_metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T18:22:57.412921Z",
     "iopub.status.busy": "2025-03-29T18:22:57.412649Z",
     "iopub.status.idle": "2025-03-29T18:22:57.415899Z",
     "shell.execute_reply": "2025-03-29T18:22:57.415220Z",
     "shell.execute_reply.started": "2025-03-29T18:22:57.412900Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import my_metrics\n",
    "# importlib.reload(my_metrics)\n",
    "# print(dir(my_metrics))  # Now should include 'batch', 'get_all_embeddings', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T18:21:33.150932Z",
     "iopub.status.busy": "2025-03-29T18:21:33.150556Z",
     "iopub.status.idle": "2025-03-29T18:21:33.154721Z",
     "shell.execute_reply": "2025-03-29T18:21:33.153972Z",
     "shell.execute_reply.started": "2025-03-29T18:21:33.150904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from my_metrics import compute_consistency_score,evaluate_model\n",
    "\n",
    "#Does below work?\n",
    "from my_metrics import batch,get_all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:31.734854Z",
     "iopub.status.busy": "2025-03-29T17:56:31.734466Z",
     "iopub.status.idle": "2025-03-29T17:56:40.559175Z",
     "shell.execute_reply": "2025-03-29T17:56:40.558490Z",
     "shell.execute_reply.started": "2025-03-29T17:56:31.734832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import open_clip\n",
    "import open_clip_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:40.560246Z",
     "iopub.status.busy": "2025-03-29T17:56:40.560034Z",
     "iopub.status.idle": "2025-03-29T17:56:40.563890Z",
     "shell.execute_reply": "2025-03-29T17:56:40.563004Z",
     "shell.execute_reply.started": "2025-03-29T17:56:40.560229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T18:20:41.007193Z",
     "iopub.status.busy": "2025-03-29T18:20:41.006878Z",
     "iopub.status.idle": "2025-03-29T18:20:41.011008Z",
     "shell.execute_reply": "2025-03-29T18:20:41.010170Z",
     "shell.execute_reply.started": "2025-03-29T18:20:41.007167Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import open_clip\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:40.761384Z",
     "iopub.status.busy": "2025-03-29T17:56:40.761096Z",
     "iopub.status.idle": "2025-03-29T17:56:40.764922Z",
     "shell.execute_reply": "2025-03-29T17:56:40.764213Z",
     "shell.execute_reply.started": "2025-03-29T17:56:40.761357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#open_clip.list_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:40.765979Z",
     "iopub.status.busy": "2025-03-29T17:56:40.765739Z",
     "iopub.status.idle": "2025-03-29T17:56:40.779355Z",
     "shell.execute_reply": "2025-03-29T17:56:40.778732Z",
     "shell.execute_reply.started": "2025-03-29T17:56:40.765960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#                Preparing train datasaet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:40.780577Z",
     "iopub.status.busy": "2025-03-29T17:56:40.780253Z",
     "iopub.status.idle": "2025-03-29T17:56:43.299081Z",
     "shell.execute_reply": "2025-03-29T17:56:43.298128Z",
     "shell.execute_reply.started": "2025-03-29T17:56:40.780546Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV file saved at: /kaggle/working/train_data_karpathy.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load Karpathy JSON file\n",
    "karpathy_json_path = \"/kaggle/input/karpathy-splits/dataset_flickr30k.json\"\n",
    "with open(karpathy_json_path, \"r\") as f:\n",
    "    karpathy_data = json.load(f)\n",
    "\n",
    "# Extract training set\n",
    "train_data = [item for item in karpathy_data[\"images\"] if item[\"split\"] == \"train\"]\n",
    "\n",
    "# Prepare data for CSV\n",
    "train_records = []\n",
    "for item in train_data:\n",
    "    img_filename = f\"/kaggle/input/flickr30k/Images/{item['filename']}\"\n",
    "    for sentence in item[\"sentences\"]:\n",
    "        caption = sentence[\"raw\"]\n",
    "        train_records.append({\"image\": img_filename, \"caption\": caption})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_train = pd.DataFrame(train_records)\n",
    "\n",
    "# Save to CSV (formatted properly)\n",
    "csv_path = \"/kaggle/working/train_data_karpathy.csv\"\n",
    "df_train.to_csv(csv_path, index=True, index_label=\"id\")\n",
    "\n",
    "print(f\"✅ CSV file saved at: {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:43.302181Z",
     "iopub.status.busy": "2025-03-29T17:56:43.301909Z",
     "iopub.status.idle": "2025-03-29T17:56:43.325509Z",
     "shell.execute_reply": "2025-03-29T17:56:43.324741Z",
     "shell.execute_reply.started": "2025-03-29T17:56:43.302159Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n",
       "      <td>Two young guys with shaggy hair look at their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n",
       "      <td>Two young, White males are outside near many b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n",
       "      <td>Two men in green shirts are standing in a yard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n",
       "      <td>A man in a blue shirt standing in a garden.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/flickr30k/Images/1000092795.jpg</td>\n",
       "      <td>Two friends enjoy time spent together.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image  \\\n",
       "0  /kaggle/input/flickr30k/Images/1000092795.jpg   \n",
       "1  /kaggle/input/flickr30k/Images/1000092795.jpg   \n",
       "2  /kaggle/input/flickr30k/Images/1000092795.jpg   \n",
       "3  /kaggle/input/flickr30k/Images/1000092795.jpg   \n",
       "4  /kaggle/input/flickr30k/Images/1000092795.jpg   \n",
       "\n",
       "                                             caption  \n",
       "0  Two young guys with shaggy hair look at their ...  \n",
       "1  Two young, White males are outside near many b...  \n",
       "2    Two men in green shirts are standing in a yard.  \n",
       "3        A man in a blue shirt standing in a garden.  \n",
       "4             Two friends enjoy time spent together.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:43.327380Z",
     "iopub.status.busy": "2025-03-29T17:56:43.327101Z",
     "iopub.status.idle": "2025-03-29T17:56:44.552843Z",
     "shell.execute_reply": "2025-03-29T17:56:44.551928Z",
     "shell.execute_reply.started": "2025-03-29T17:56:43.327355Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "karpathy_json_path = \"/kaggle/input/karpathy-splits/dataset_flickr30k.json\"\n",
    "with open(karpathy_json_path, \"r\") as f:\n",
    "    karpathy_data = json.load(f)\n",
    "\n",
    "# Extract test set\n",
    "test_data = [item for item in karpathy_data[\"images\"] if item[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:44.554227Z",
     "iopub.status.busy": "2025-03-29T17:56:44.553900Z",
     "iopub.status.idle": "2025-03-29T17:56:44.645365Z",
     "shell.execute_reply": "2025-03-29T17:56:44.644476Z",
     "shell.execute_reply.started": "2025-03-29T17:56:44.554194Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:44.646811Z",
     "iopub.status.busy": "2025-03-29T17:56:44.646380Z",
     "iopub.status.idle": "2025-03-29T17:56:44.660552Z",
     "shell.execute_reply": "2025-03-29T17:56:44.659754Z",
     "shell.execute_reply.started": "2025-03-29T17:56:44.646776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Standard loading\n",
    "# model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "# model = model.to(device)\n",
    "# model.eval()  # model in train mode by default, impacts some models with BatchNorm or stochastic depth active\n",
    "# tokenizer = open_clip.get_tokenizer('ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:44.661501Z",
     "iopub.status.busy": "2025-03-29T17:56:44.661302Z",
     "iopub.status.idle": "2025-03-29T17:56:46.509057Z",
     "shell.execute_reply": "2025-03-29T17:56:46.508372Z",
     "shell.execute_reply.started": "2025-03-29T17:56:44.661476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# FOR CYCLIP PRE TRAINED THAT I HAVE DOWNLOADED LOCALLY\n",
    "model_clip_3M, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    model_name=\"RN50\",\n",
    "    pretrained=None,  # Don't load default weights\n",
    "    precision='fp32', # or 'amp' for mixed precision\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:46.510092Z",
     "iopub.status.busy": "2025-03-29T17:56:46.509847Z",
     "iopub.status.idle": "2025-03-29T17:56:53.851317Z",
     "shell.execute_reply": "2025-03-29T17:56:53.850453Z",
     "shell.execute_reply.started": "2025-03-29T17:56:46.510071Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-8c7501dc18c2>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"/kaggle/input/clip-3m-from-cyclip/clip-3M.pt/best.pt\", map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): ModifiedResNet(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act3): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (attnpool): AttentionPool2d(\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the checkpoint - OG CLIP - 3M\n",
    "ckpt = torch.load(\"/kaggle/input/clip-3m-from-cyclip/clip-3M.pt/best.pt\", map_location=device)\n",
    "state_dict = ckpt[\"state_dict\"]\n",
    "\n",
    "# Remove 'module.' prefix from keys\n",
    "new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "\n",
    "# Load into your model\n",
    "model_clip_3M.load_state_dict(new_state_dict)\n",
    "model_clip_3M.to(device)\n",
    "model_clip_3M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:53.852397Z",
     "iopub.status.busy": "2025-03-29T17:56:53.852097Z",
     "iopub.status.idle": "2025-03-29T17:56:55.335330Z",
     "shell.execute_reply": "2025-03-29T17:56:55.334631Z",
     "shell.execute_reply.started": "2025-03-29T17:56:53.852364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# FOR CYCLIP PRE TRAINED THAT I HAVE DOWNLOADED LOCALLY\n",
    "model_Cyclip_3M, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    model_name=\"RN50\",\n",
    "    pretrained=None,  # Don't load default weights\n",
    "    precision='fp32', # or 'amp' for mixed precision\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:56:55.336280Z",
     "iopub.status.busy": "2025-03-29T17:56:55.336056Z",
     "iopub.status.idle": "2025-03-29T17:57:01.616298Z",
     "shell.execute_reply": "2025-03-29T17:57:01.615482Z",
     "shell.execute_reply.started": "2025-03-29T17:56:55.336263Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-46b685d1e9da>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"/kaggle/input/cyclip-3m/CYCLIP-3M_best.pt\", map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): ModifiedResNet(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act3): ReLU(inplace=True)\n",
       "    (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (-1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (avgpool): Identity()\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (attnpool): AttentionPool2d(\n",
       "      (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (c_proj): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the checkpoint - CY CLIP - 3M\n",
    "ckpt = torch.load(\"/kaggle/input/cyclip-3m/CYCLIP-3M_best.pt\", map_location=device)\n",
    "state_dict = ckpt[\"state_dict\"]\n",
    "\n",
    "# Remove 'module.' prefix from keys\n",
    "new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "\n",
    "# Load into your model\n",
    "model_Cyclip_3M.load_state_dict(new_state_dict)\n",
    "model_Cyclip_3M.to(device)\n",
    "model_Cyclip_3M.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:57:01.617215Z",
     "iopub.status.busy": "2025-03-29T17:57:01.617005Z",
     "iopub.status.idle": "2025-03-29T17:57:01.721425Z",
     "shell.execute_reply": "2025-03-29T17:57:01.720497Z",
     "shell.execute_reply.started": "2025-03-29T17:57:01.617192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Tokenizer for my models\n",
    "tokenizer = open_clip.get_tokenizer('RN50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:57:01.722574Z",
     "iopub.status.busy": "2025-03-29T17:57:01.722342Z",
     "iopub.status.idle": "2025-03-29T17:57:01.726028Z",
     "shell.execute_reply": "2025-03-29T17:57:01.725187Z",
     "shell.execute_reply.started": "2025-03-29T17:57:01.722554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# open_clip.list_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:57:01.726963Z",
     "iopub.status.busy": "2025-03-29T17:57:01.726767Z",
     "iopub.status.idle": "2025-03-29T17:57:01.744155Z",
     "shell.execute_reply": "2025-03-29T17:57:01.743417Z",
     "shell.execute_reply.started": "2025-03-29T17:57:01.726946Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#           TO FINE TUNE\n",
    "#!python /kaggle/working/open-clip/src/open_clip_train/main.py \\\n",
    "#     --train-data /kaggle/working/train_data_karpathy.csv \\\n",
    "#     --dataset-type csv \\\n",
    "#     --csv-img-key image \\\n",
    "#     --csv-caption-key caption \\\n",
    "#     --csv-separator \",\" \\\n",
    "#     --model ViT-B-32 \\\n",
    "#     --pretrained 'laion2b_s34b_b79k' \\\n",
    "#     --batch-size 48 \\\n",
    "#     --lr 5e-6 \\\n",
    "#     --warmup 1000 \\\n",
    "#     --epochs 1 \\\n",
    "#     --lr-scheduler cosine \\\n",
    "#     --precision amp \\\n",
    "#     --workers 4 \\\n",
    "#     --logs \"logs\" \\\n",
    "#     --logs \"checkpoints\" \\\n",
    "#     --save-frequency 1 \\\n",
    "#     --seed 42 \\\n",
    "#     --lambda_dino 0.25 \\\n",
    "#     #--use_soft_labels \\\n",
    "#     --soft_temprature 0.05 \\\n",
    "#     --alpha 0  \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:57:01.745248Z",
     "iopub.status.busy": "2025-03-29T17:57:01.744958Z",
     "iopub.status.idle": "2025-03-29T17:57:01.759517Z",
     "shell.execute_reply": "2025-03-29T17:57:01.758837Z",
     "shell.execute_reply.started": "2025-03-29T17:57:01.745227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !ls checkpoints/2025_03_21-13_51_26-model_ViT-B-32-lr_5e-06-b_48-j_4-p_amp/checkpoints  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:57:01.760616Z",
     "iopub.status.busy": "2025-03-29T17:57:01.760391Z",
     "iopub.status.idle": "2025-03-29T17:57:01.775627Z",
     "shell.execute_reply": "2025-03-29T17:57:01.774630Z",
     "shell.execute_reply.started": "2025-03-29T17:57:01.760586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import open_clip\n",
    "\n",
    "# # Path to your trained checkpoint\n",
    "# checkpoint_path = \"checkpoints/2025_03_21-13_51_26-model_ViT-B-32-lr_5e-06-b_48-j_4-p_amp/checkpoints/epoch_1.pt\"\n",
    "\n",
    "# # 1. Create the model architecture from scratch (without loading pretrained weights)\n",
    "# model_ft_mod, preprocess_ft, preprocess_val = open_clip.create_model_and_transforms(\n",
    "#     \"ViT-B-32\", pretrained=None\n",
    "# )\n",
    "\n",
    "# # 2. Load the trained checkpoint manually\n",
    "# checkpoint = torch.load(checkpoint_path, map_location=\"cpu\",weights_only=True)\n",
    "\n",
    "# # If the state_dict is nested under a key (like \"state_dict\"), adjust accordingly\n",
    "# if \"state_dict\" in checkpoint:\n",
    "#     checkpoint = checkpoint[\"state_dict\"]\n",
    "\n",
    "# # Load checkpoint weights into model\n",
    "# model_ft_mod.load_state_dict(checkpoint, strict=False)  # Use strict=False to avoid missing keys error\n",
    "\n",
    "# # 3. Move model to GPU (if available)\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model_ft_mod = model_ft_mod.to(device)\n",
    "#model_ft_mod.eval()\n",
    "# print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:57:01.776637Z",
     "iopub.status.busy": "2025-03-29T17:57:01.776450Z",
     "iopub.status.idle": "2025-03-29T17:57:01.787398Z",
     "shell.execute_reply": "2025-03-29T17:57:01.786612Z",
     "shell.execute_reply.started": "2025-03-29T17:57:01.776621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#FROM CYCLIP\n",
    "def get_all_embeddings(model, all_texts, all_images, root, preprocess, tokenizer, batch_size=1024, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    text_embeddings = []\n",
    "    image_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dataloader_texts = list(batch(all_texts, batch_size))\n",
    "        dataloader_images = list(batch(all_images, batch_size))\n",
    "\n",
    "        bar = zip(dataloader_texts, dataloader_images)\n",
    "        bar = tqdm(bar, total=len(dataloader_texts), desc=\"Encoding batches\")\n",
    "\n",
    "        for texts, images in bar:\n",
    "            # Tokenize text\n",
    "            text_tokens = tokenizer(texts).to(device)\n",
    "\n",
    "            # Preprocess and stack images\n",
    "            image_tensors = torch.stack([\n",
    "                preprocess(Image.open(os.path.join(root, img)).convert(\"RGB\"))\n",
    "                for img in images\n",
    "            ]).to(device)\n",
    "\n",
    "            # Encode\n",
    "            image_embedding = model.encode_image(image_tensors)\n",
    "            text_embedding = model.encode_text(text_tokens)\n",
    "\n",
    "            # Normalize\n",
    "            text_embedding /= text_embedding.norm(dim=-1, keepdim=True)\n",
    "            image_embedding /= image_embedding.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            text_embeddings.append(text_embedding)\n",
    "            image_embeddings.append(image_embedding)\n",
    "\n",
    "        text_embeddings = torch.cat(text_embeddings)\n",
    "        image_embeddings = torch.cat(image_embeddings)\n",
    "        return text_embeddings, image_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:57:01.788590Z",
     "iopub.status.busy": "2025-03-29T17:57:01.788281Z",
     "iopub.status.idle": "2025-03-29T17:57:01.808577Z",
     "shell.execute_reply": "2025-03-29T17:57:01.807757Z",
     "shell.execute_reply.started": "2025-03-29T17:57:01.788560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#FROM CYCLIP\n",
    "\n",
    "@torch.no_grad()\n",
    "def itm_eval(text_embeddings, image_embeddings):\n",
    "\n",
    "    # sim_matrix_i2t = image_embeddings @ text_embeddings.t()\n",
    "    # sim_matrix_t2i = text_embeddings @ image_embeddings.t()\n",
    "\n",
    "    ## Image -> Text\n",
    "    # ranks = np.zeros(len(sim_matrix_i2t))\n",
    "    ranks = np.zeros(len(image_embeddings))\n",
    "\n",
    "    for index in range(0, len(image_embeddings), 5):\n",
    "        scores = image_embeddings[index] @ text_embeddings.t()\n",
    "        # scores = sim_matrix_i2t[index]\n",
    "        li = np.argsort(scores.detach().cpu().numpy())[::-1]\n",
    "        for i in range(len(li)):\n",
    "            if index <= li[i] and li[i] <= index + 4:\n",
    "                rank = i\n",
    "                break\n",
    "        ranks[index] = rank\n",
    "    \n",
    "        # Compute metrics\n",
    "    tr1 = 100.0 * len(np.where(ranks < 1)[0]) / len(ranks)\n",
    "    tr5 = 100.0 * len(np.where(ranks < 5)[0]) / len(ranks)\n",
    "    tr10 = 100.0 * len(np.where(ranks < 10)[0]) / len(ranks)\n",
    "\n",
    "    ## Image -> Text\n",
    "    ranks = np.zeros(len(text_embeddings))\n",
    "    for index in range(len(text_embeddings)):\n",
    "        scores = text_embeddings[index] @ image_embeddings.t()\n",
    "    # for index, scores in tqdm(enumerate(sim_matrix_t2i)):\n",
    "        scores = scores[::5]\n",
    "        li = np.argsort(scores.detach().cpu().numpy())[::-1]\n",
    "        for i in range(len(li)):\n",
    "            if li[i] == index//5:\n",
    "                rank = i\n",
    "                break\n",
    "        ranks[index] = rank\n",
    "    \n",
    "    # Compute metrics\n",
    "    ir1 = 100.0 * len(np.where(ranks < 1)[0]) / len(ranks)\n",
    "    ir5 = 100.0 * len(np.where(ranks < 5)[0]) / len(ranks)\n",
    "    ir10 = 100.0 * len(np.where(ranks < 10)[0]) / len(ranks)\n",
    "    \n",
    "    tr_mean = (tr1 + tr5 + tr10) / 3\n",
    "    ir_mean = (ir1 + ir5 + ir10) / 3\n",
    "    r_mean = (tr_mean + ir_mean) / 2\n",
    "\n",
    "    eval_result =  {'txt_r1': tr1,\n",
    "                'txt_r5': tr5,\n",
    "                'txt_r10': tr10,\n",
    "                'txt_r_mean': tr_mean,\n",
    "                'img_r1': ir1,\n",
    "                'img_r5': ir5,\n",
    "                'img_r10': ir10,\n",
    "                'img_r_mean': ir_mean,\n",
    "                'r_mean': r_mean}\n",
    "\n",
    "    return eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:58:17.145691Z",
     "iopub.status.busy": "2025-03-29T17:58:17.145330Z",
     "iopub.status.idle": "2025-03-29T17:58:17.150193Z",
     "shell.execute_reply": "2025-03-29T17:58:17.149126Z",
     "shell.execute_reply.started": "2025-03-29T17:58:17.145640Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def batch(iterable, n = 1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T17:57:01.809485Z",
     "iopub.status.busy": "2025-03-29T17:57:01.809292Z",
     "iopub.status.idle": "2025-03-29T17:57:01.845492Z",
     "shell.execute_reply": "2025-03-29T17:57:01.844770Z",
     "shell.execute_reply.started": "2025-03-29T17:57:01.809462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_data = [item for item in karpathy_data[\"images\"] if item[\"split\"] == \"test\"]\n",
    "all_captions = []\n",
    "all_images = []\n",
    "for item in test_data:\n",
    "    for sentence in item[\"sentences\"]:\n",
    "        all_captions.append(sentence[\"raw\"])\n",
    "        all_images.append(item[\"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T18:01:10.556182Z",
     "iopub.status.busy": "2025-03-29T18:01:10.555831Z",
     "iopub.status.idle": "2025-03-29T18:02:18.853049Z",
     "shell.execute_reply": "2025-03-29T18:02:18.852112Z",
     "shell.execute_reply.started": "2025-03-29T18:01:10.556157Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding batches: 100%|██████████| 105/105 [01:08<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute embeddings\n",
    "#FROM CYCLIP\n",
    "\n",
    "image_root = \"/kaggle/input/flickr30k/Images\"\n",
    "text_embeds, image_embeds = get_all_embeddings(\n",
    "    model_Cyclip_3M, all_captions, all_images, root=image_root,\n",
    "    preprocess=preprocess, tokenizer=tokenizer, device=device , batch_size=48\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T18:02:43.169127Z",
     "iopub.status.busy": "2025-03-29T18:02:43.168829Z",
     "iopub.status.idle": "2025-03-29T18:02:44.425016Z",
     "shell.execute_reply": "2025-03-29T18:02:44.424057Z",
     "shell.execute_reply.started": "2025-03-29T18:02:43.169107Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation Results:\n",
      "txt_r1: 87.78\n",
      "txt_r5: 92.96\n",
      "txt_r10: 95.10\n",
      "txt_r_mean: 91.95\n",
      "img_r1: 26.66\n",
      "img_r5: 52.84\n",
      "img_r10: 64.16\n",
      "img_r_mean: 47.89\n",
      "r_mean: 69.92\n"
     ]
    }
   ],
   "source": [
    "#FROM CYCLIP\n",
    "# Evaluate\n",
    "results = itm_eval(text_embeds, image_embeds)\n",
    "print(\"📊 Evaluation Results:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T18:21:54.018496Z",
     "iopub.status.busy": "2025-03-29T18:21:54.018168Z",
     "iopub.status.idle": "2025-03-29T18:22:57.411588Z",
     "shell.execute_reply": "2025-03-29T18:22:57.410726Z",
     "shell.execute_reply.started": "2025-03-29T18:21:54.018468Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding batches: 100%|██████████| 105/105 [01:03<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "image_root = \"/kaggle/input/flickr30k/Images\"\n",
    "text_embeds, image_embeds = get_all_embeddings(\n",
    "    model_clip_3M, all_captions, all_images, root=image_root,\n",
    "    preprocess=preprocess, tokenizer=tokenizer, device=device , batch_size=48\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T18:23:28.519829Z",
     "iopub.status.busy": "2025-03-29T18:23:28.519479Z",
     "iopub.status.idle": "2025-03-29T18:23:29.767405Z",
     "shell.execute_reply": "2025-03-29T18:23:29.766605Z",
     "shell.execute_reply.started": "2025-03-29T18:23:28.519801Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation Results:\n",
      "txt_r1: 88.18\n",
      "txt_r5: 93.42\n",
      "txt_r10: 95.56\n",
      "txt_r_mean: 92.39\n",
      "img_r1: 26.20\n",
      "img_r5: 53.32\n",
      "img_r10: 65.52\n",
      "img_r_mean: 48.35\n",
      "r_mean: 70.37\n"
     ]
    }
   ],
   "source": [
    "#FROM CYCLIP\n",
    "# Evaluate\n",
    "results = itm_eval(text_embeds, image_embeds)\n",
    "print(\"📊 Evaluation Results:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T18:03:03.221783Z",
     "iopub.status.busy": "2025-03-29T18:03:03.221395Z",
     "iopub.status.idle": "2025-03-29T18:03:56.843868Z",
     "shell.execute_reply": "2025-03-29T18:03:56.842918Z",
     "shell.execute_reply.started": "2025-03-29T18:03:03.221750Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 1000/1000 [00:52<00:00, 18.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 1000 image features and 5000 text features.\n",
      "Top-1 Accuracy: 26.66%\n",
      "Top-5 Accuracy: 52.84%\n",
      "Top-10 Accuracy: 64.16%\n"
     ]
    }
   ],
   "source": [
    "# OG CLIP - 3M\n",
    "df_results_model = evaluate_model(\n",
    "    model=model_Cyclip_3M,\n",
    "    preprocess=preprocess,\n",
    "    tokenizer=tokenizer,\n",
    "    test_data=test_data,  # Reuse preloaded test data\n",
    "    image_folder=\"/kaggle/input/flickr30k/Images\",\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T18:03:56.845417Z",
     "iopub.status.busy": "2025-03-29T18:03:56.845136Z",
     "iopub.status.idle": "2025-03-29T18:04:50.893131Z",
     "shell.execute_reply": "2025-03-29T18:04:50.892163Z",
     "shell.execute_reply.started": "2025-03-29T18:03:56.845395Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 1000/1000 [00:53<00:00, 18.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 1000 image features and 5000 text features.\n",
      "Top-1 Accuracy: 26.20%\n",
      "Top-5 Accuracy: 53.32%\n",
      "Top-10 Accuracy: 65.52%\n"
     ]
    }
   ],
   "source": [
    "# CY CLIP - 3M\n",
    "\n",
    "df_results_model = evaluate_model(\n",
    "    model=model_clip_3M,\n",
    "    preprocess=preprocess,\n",
    "    tokenizer=tokenizer,\n",
    "    test_data=test_data,  # Reuse preloaded test data\n",
    "    image_folder=\"/kaggle/input/flickr30k/Images\",\n",
    "    device=device\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 21870,
     "sourceId": 285971,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 623329,
     "sourceId": 1111749,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1011404,
     "sourceId": 1706129,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
